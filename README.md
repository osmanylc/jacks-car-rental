In this repo we solve exercise 4.7 from Sutton and Barto.

The problem asks us to solve a simple MDP using policy iteration.

